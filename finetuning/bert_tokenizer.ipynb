{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert_tokenizer.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1MoN1mBR-mowcgCnpXXIa1T_0AEB0xlhx","authorship_tag":"ABX9TyMnbmEd00d657dBmsd7Fcwd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"fcVxmj4op3xn"},"source":["# We won't need TensorFlow here\n","!pip uninstall -y tensorflow\n","# Install `transformers` from master\n","!pip install git+https://github.com/huggingface/transformers\n","!pip list | grep -E 'transformers|tokenizers'\n","# transformers version at notebook update --- 2.11.0\n","# tokenizers version at notebook update --- 0.8.0rc1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i9SzrLbip78Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625557334848,"user_tz":-180,"elapsed":698953,"user":{"displayName":"z erva erg√ºn","photoUrl":"","userId":"16255015835614953460"}},"outputId":"95192397-500a-4afa-c92d-446d89892222"},"source":["%%time \n","from pathlib import Path\n","\n","from tokenizers import BertWordPieceTokenizer\n","\n","#paths = [str(x) for x in Path(\".\").glob(\"**/*.txt\")]\n","paths = r\"/content/drive/MyDrive/100mbout/nout2006.txt\"\n","# Initialize a tokenizer\n","tokenizer = BertWordPieceTokenizer()\n","\n","# Customize training\n","tokenizer.train(files=paths, vocab_size=52_000, min_frequency=2,special_tokens=[\n","                \"[UNK]\",\n","                \"[SEP]\",\n","                \"[PAD]\",\n","                \"[CLS]\",\n","                \"[MASK]\",                                                               \n","\n","              ])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CPU times: user 22min 11s, sys: 9.28 s, total: 22min 21s\n","Wall time: 11min 38s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W3vjMoLAqD66","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625557339666,"user_tz":-180,"elapsed":430,"user":{"displayName":"z erva erg√ºn","photoUrl":"","userId":"16255015835614953460"}},"outputId":"a4426b1d-f312-469f-e5d9-a64c4f22d5d9"},"source":["!mkdir bert\n","tokenizer.save_model(\"bert\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['bert/vocab.txt']"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"nlJvH918szsz","executionInfo":{"status":"ok","timestamp":1625557732992,"user_tz":-180,"elapsed":338,"user":{"displayName":"z erva erg√ºn","photoUrl":"","userId":"16255015835614953460"}}},"source":["from tokenizers.implementations import BertWordPieceTokenizer\n","from tokenizers.processors import BertProcessing\n","\n","\n","tokenizer = BertWordPieceTokenizer(\n","    \"./bert/vocab.txt\",\n","    \n",")"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"mrx7IMXGs0g_","executionInfo":{"status":"ok","timestamp":1625557735620,"user_tz":-180,"elapsed":394,"user":{"displayName":"z erva erg√ºn","photoUrl":"","userId":"16255015835614953460"}}},"source":["tokenizer._tokenizer.post_processor = BertProcessing(\n","    (\"[SEP]\", tokenizer.token_to_id(\"[SEP]\")),\n","    (\"[CLS]\", tokenizer.token_to_id(\"[CLS]\")),\n",")\n","tokenizer.enable_truncation(max_length=512)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"ABDKwfM9xTIY","executionInfo":{"status":"ok","timestamp":1625557737614,"user_tz":-180,"elapsed":397,"user":{"displayName":"z erva erg√ºn","photoUrl":"","userId":"16255015835614953460"}}},"source":["from transformers import BertConfig\n","\n","config = BertConfig(\n","    vocab_size=52_000,\n","    max_position_embeddings=514,\n","    num_attention_heads=12,\n","    num_hidden_layers=6,\n","    type_vocab_size=1,\n",")"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"NXYDwNAyxWD5","executionInfo":{"status":"ok","timestamp":1625557741194,"user_tz":-180,"elapsed":458,"user":{"displayName":"z erva erg√ºn","photoUrl":"","userId":"16255015835614953460"}}},"source":["from transformers import BertTokenizerFast\n","\n","tokenizer = BertTokenizerFast.from_pretrained(\"./bert\", max_len=512)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"m01fXPxixYvn","executionInfo":{"status":"ok","timestamp":1625557745176,"user_tz":-180,"elapsed":2504,"user":{"displayName":"z erva erg√ºn","photoUrl":"","userId":"16255015835614953460"}}},"source":["from transformers import BertForMaskedLM\n","\n","model = BertForMaskedLM(config=config)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"99_wlYezxbEZ","executionInfo":{"status":"ok","timestamp":1625557746453,"user_tz":-180,"elapsed":12,"user":{"displayName":"z erva erg√ºn","photoUrl":"","userId":"16255015835614953460"}},"outputId":"9a434b7f-d99d-48ea-89d6-d19553b59e34"},"source":["model.num_parameters()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["83504416"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"xKt36c5Wy2dJ"},"source":["!pip install datasets"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H2ssdtKEy2-Q"},"source":["!pip install git+https://github.com/huggingface/transformers\n","!git clone https://github.com/huggingface/transformers.git\n","!pip list | grep -E 'transformers|tokenizers'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y4DfPxkjy9d1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"43qJEl-IBgfY"},"source":["!python /content/transformers/examples/pytorch/language-modeling/run_plm.py \\\n","    --train_file \"/content/drive/MyDrive/100mbout/200mb/nout2006.txt\" \\\n","    --tokenizer_name \"/content/xlnet\" \\\n","    --do_train \\\n","    --max_steps 1000 \\\n","    --pad_to_max_length True \\\n","    --output_dir /content/output_xlnet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UNfHRF1exeTn","outputId":"c79b0fd5-37f4-4cb7-a89d-6a25cfc07123"},"source":["from transformers import LineByLineTextDataset\n","\n","dataset = LineByLineTextDataset(\n","    tokenizer=tokenizer,\n","    file_path=\"/content/drive/MyDrive/100mbout/nout2006.txt\",\n","    block_size=128,\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:124: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"EqeCG3k1xk0U"},"source":["from transformers import DataCollatorForLanguageModeling\n","\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Z6I_wscxloc"},"source":["from transformers import Trainer, TrainingArguments\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./bert\",\n","    max_steps = 1000,\n","    overwrite_output_dir=True,\n","    num_train_epochs=1,\n","    per_gpu_train_batch_size=64,\n","    save_steps=10_000,\n","    save_total_limit=2,\n","    prediction_loss_only=True,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=dataset,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xi6lQV1QxobT"},"source":["%%time\n","trainer.train()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jsx5psZ_xqWs"},"source":["trainer.save_model(\"./bert\")"],"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"xlnet-kisa.ipynb","provenance":[{"file_id":"1EiuClYk6bj_9ZMny16AEZYerozN_4GnJ","timestamp":1620604716930},{"file_id":"https://github.com/huggingface/blog/blob/master/notebooks/01_how_to_train.ipynb","timestamp":1620604112761}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5duRggBRZKvP"},"source":["# We won't need TensorFlow here\n","!pip uninstall -y tensorflow\n","!pip install sentencepiece\n","# Install `transformers` from master\n","!pip install git+https://github.com/huggingface/transformers\n","!pip list | grep -E 'transformers|tokenizers'\n","# transformers version at notebook update --- 2.11.0\n","# tokenizers version at notebook update --- 0.8.0rc1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a0ICuIN4k0G9"},"source":["import sentencepiece as spm \n","spm.SentencePieceTrainer.Train('--input=/content/drive/MyDrive/100mbout/out2006_3.txt --vocab_size=52000 --model_prefix=sp10m.cased.v3 --character_coverage=0.99995 --model_type=unigram')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XAelMeiBTaVJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620604925331,"user_tz":-180,"elapsed":23090,"user":{"displayName":"z erva erg√ºn","photoUrl":"","userId":"16255015835614953460"}},"outputId":"d2af634e-47d7-4976-c70c-9d06cae8e28b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LTXXutqeDzPi"},"source":["from transformers import XLNetConfig\n","\n","config = XLNetConfig(\n","    vocab_size=52000,\n","    d_model = 32,\n","    #max_position_embeddings=514,\n","    n_head=4,\n","    n_layer=6,\n","    #d_inner=32,\n","    #d_model=32,\n","    dropout=0.1,\n","    dropatt=0.1,\n","    attn_type=\"bi\", \n","    clamp_len=-1,\n","    same_length=False,\n","    mem_len = 1024\n","    #type_vocab_size=1,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EWEUg21Vn5Fq"},"source":["from transformers import XLNetModel\n","model = XLNetModel(config=config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4keFBUjQFOD1"},"source":["from transformers import XLNetTokenizerFast\n","\n","tokenizer = XLNetTokenizerFast(\"/content/xlnet/sp10m.cased.v3.model\", max_len=512)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8yyNK3LOph08","executionInfo":{"status":"ok","timestamp":1620606201107,"user_tz":-180,"elapsed":3550,"user":{"displayName":"z erva erg√ºn","photoUrl":"","userId":"16255015835614953460"}},"outputId":"718ffc2c-7228-49fb-df06-f8ea81692abf"},"source":["!pip install torch"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WouBud47pTaR"},"source":["import io\n","import os\n","import math\n","import torch\n","import warnings\n","from tqdm.notebook import tqdm\n","from transformers import (\n","                          CONFIG_MAPPING,\n","                          MODEL_FOR_MASKED_LM_MAPPING,\n","                          MODEL_FOR_CAUSAL_LM_MAPPING,\n","                          PreTrainedTokenizer,\n","                          TrainingArguments,\n","                          AutoConfig,\n","                          AutoTokenizer,\n","                          AutoModelWithLMHead,\n","                          AutoModelForCausalLM,\n","                          AutoModelForMaskedLM,\n","                          LineByLineTextDataset,\n","                          TextDataset,\n","                          DataCollatorForLanguageModeling,\n","                          DataCollatorForWholeWordMask,\n","                          DataCollatorForPermutationLanguageModeling,\n","                          PretrainedConfig,\n","                          Trainer,\n","                          set_seed,\n","                          )\n","model = AutoModelWithLMHead.from_config(config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jU6JhBSTKiaM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620606231903,"user_tz":-180,"elapsed":779,"user":{"displayName":"z erva erg√ºn","photoUrl":"","userId":"16255015835614953460"}},"outputId":"55fd5623-3183-4a5a-9dcc-b2be236e6b93"},"source":["model.num_parameters()\n","# => 84 million parameters"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3346112"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"GlvP_A-THEEl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620606338473,"user_tz":-180,"elapsed":101471,"user":{"displayName":"z erva erg√ºn","photoUrl":"","userId":"16255015835614953460"}},"outputId":"f672cb7a-7a02-411e-b4d2-d12d75ca5f46"},"source":["%%time\n","from transformers import LineByLineTextDataset\n","\n","dataset = LineByLineTextDataset(\n","    tokenizer=tokenizer,\n","    file_path=\"/content/drive/MyDrive/100mbout/out2006_3.txt\",\n","    block_size=128,\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:124: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["CPU times: user 4min 26s, sys: 8.36 s, total: 4min 34s\n","Wall time: 1min 40s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zTgWPa9Dipk2"},"source":["from transformers import DataCollatorForLanguageModeling, DataCollatorForPermutationLanguageModeling\n","\n","#data_collator = DataCollatorForLanguageModeling(\n","#    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n","#)\n","plm_probability=1 / 6\n","max_span_length= 5\n","data_collator = DataCollatorForPermutationLanguageModeling(\n","                                          tokenizer=tokenizer,\n","                                          plm_probability=plm_probability,\n","                                          max_span_length=max_span_length,\n","                                          )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YpvnFFmZJD-N"},"source":["from transformers import Trainer, TrainingArguments\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./xlnet\",\n","    max_steps = 1000,\n","    overwrite_output_dir=True,\n","    num_train_epochs=1,\n","    per_gpu_train_batch_size=64,\n","    save_steps=10_000,\n","    save_total_limit=2,\n","    prediction_loss_only=True,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=dataset,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o6sASa36Nf-N"},"source":["### Start training"]},{"cell_type":"code","metadata":{"id":"VmaHZXzmkNtJ","colab":{"base_uri":"https://localhost:8080/","height":269},"executionInfo":{"status":"ok","timestamp":1620606701917,"user_tz":-180,"elapsed":248397,"user":{"displayName":"z erva erg√ºn","photoUrl":"","userId":"16255015835614953460"}},"outputId":"60380f30-a725-491d-edbf-eb2773d1dcf1"},"source":["%%time\n","trainer.train()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n","Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n","Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1000/1000 04:05, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>10.428700</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>9.973000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["CPU times: user 5min 46s, sys: 2min 24s, total: 8min 11s\n","Wall time: 4min 7s\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1000, training_loss=10.20087744140625, metrics={'train_runtime': 246.1444, 'train_samples_per_second': 4.063, 'total_flos': 164450108325888.0, 'epoch': 0.06, 'init_mem_cpu_alloc_delta': 0, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 0, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 28536832, 'train_mem_gpu_alloc_delta': 48717312, 'train_mem_cpu_peaked_delta': 0, 'train_mem_gpu_peaked_delta': 11243222016})"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"QDNgPls7_l13"},"source":["trainer.save_model(\"./xlnet\")"],"execution_count":null,"outputs":[]}]}